{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "import pandas as pd\n",
    "\n",
    "### this notebook provides an example corresponding to Table.3 in the paper.\n",
    "\n",
    "SEED = 0\n",
    "SPLIT = \"light_and_dark_flex_to_dark\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('../data_splits/Fitz_subset.csv')\n",
    "\n",
    "### sample flexible subset\n",
    "skin_type_list = [1,2,5,6]\n",
    "df = df_all[\n",
    "    (df_all['fitzpatrick_scale'].isin(skin_type_list))\n",
    "].copy()\n",
    "\n",
    "### for each condition sample 8 images FST = [5,6] respectively. \n",
    "df_flex_dark = (\n",
    "    df[df['fitzpatrick_scale'].isin([5, 6])]\n",
    "      .groupby(['label'], group_keys=False)\n",
    "      .sample(n=8, random_state=SEED, replace=False)\n",
    ")\n",
    "\n",
    "df_flex_light = (\n",
    "    df[df['fitzpatrick_scale'].isin([1, 2])]\n",
    "      .groupby(['label'], group_keys=False)\n",
    "      .sample(n=8, random_state=SEED, replace=False)\n",
    ")\n",
    "\n",
    "### remove flexible subsets \n",
    "df_non_flex = df[~df['md5hash'].isin(df_flex_dark['md5hash']) &\n",
    "                 ~df['md5hash'].isin(df_flex_light['md5hash'])]\n",
    "\n",
    "df_train = df_non_flex[df_non_flex['fitzpatrick_scale'].isin([1, 2])]\n",
    "df_train = pd.concat([df_train, df_flex_dark], ignore_index=True)\n",
    "\n",
    "df_test = df_non_flex[df_non_flex['fitzpatrick_scale'].isin([5, 6])] \n",
    "\n",
    "### save files\n",
    "df_train.to_csv(f'../data_splits/train_{SPLIT}_seed={SEED}.csv')\n",
    "df_test.to_csv(f'../data_splits/test_{SPLIT}_seed={SEED}.csv')\n",
    "\n",
    "\n",
    "### quick check\n",
    "print(df_train.shape, df_test.shape)\n",
    "print(df_train['fitzpatrick_scale'].value_counts())\n",
    "print(df_test['fitzpatrick_scale'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_list = [\"basal_cell_carcinoma\",  \n",
    "                  \"folliculitis\",\n",
    "                  \"nematode_infection\",\n",
    "                  \"neutrophilic_dermatoses\",\n",
    "                  \"prurigo_nodularis\", \n",
    "                  \"psoriasis\", \n",
    "                  \"squamous_cell_carcinoma\"]\n",
    "\n",
    "MODEL_NAME=\"stabilityai/stable-diffusion-2-1-base\"\n",
    "TRAIN_DIR=\"/data/derm_data/Fitzpatrick17k/finalfitz17k/\" # image folder\n",
    "TRAIN_SPLIT=f\"../data_splits/train_{SPLIT}_seed={SEED}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Textual Inversion \n",
    "\n",
    "for c in condition_list:\n",
    "    OUTPUT_DIR=f\"../models/textual_inversion/{SPLIT}_seed={SEED}/{c}\" \n",
    "    TOKEN=f'{c[:3]}-class'\n",
    "\n",
    "    !accelerate launch ../scripts/textual_inversion.py \\\n",
    "        --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "        --train_data_dir=$TRAIN_DIR \\\n",
    "        --fitz_split_csv=$TRAIN_SPLIT \\\n",
    "        --learnable_property=\"object\" \\\n",
    "        --placeholder_token=$TOKEN \\\n",
    "        --initializer_token=\"skin\" \\\n",
    "        --resolution=512 \\\n",
    "        --train_batch_size=4 \\\n",
    "        --gradient_accumulation_steps=4 \\\n",
    "        --mixed_precision=\"fp16\" \\\n",
    "        --max_train_steps=500 \\\n",
    "        --learning_rate=5.0e-04 \\\n",
    "        --scale_lr \\\n",
    "        --lr_scheduler=\"constant\" \\\n",
    "        --lr_warmup_steps=0 \\\n",
    "        --output_dir=$OUTPUT_DIR \\\n",
    "        --class_name=$c \\\n",
    "        --repeats=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge all the learned embeddings into a single file\n",
    "\n",
    "TI_OUTPUT_DIR = f\"../models/textual_inversion/{SPLIT}_seed={SEED}\"\n",
    "path = f\"{TI_OUTPUT_DIR}/*/learned_embeds.safetensors\"\n",
    "merged_dict = dict()\n",
    "for file in glob.glob(path):\n",
    "    tensors = {}\n",
    "    with safe_open(file, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            tensors[key] = f.get_tensor(key)\n",
    "        merged_dict.update(tensors)\n",
    "\n",
    "TI_EMBED_PATH = f\"{TI_OUTPUT_DIR}/aggregated_embeds_SEED={SEED}.pt\"\n",
    "os.makedirs(os.path.dirname(TI_EMBED_PATH), exist_ok=True)\n",
    "torch.save(merged_dict, TI_EMBED_PATH)\n",
    "print(merged_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "### let's create a json file to manage the training data\n",
    "\n",
    "token_mapper ={\n",
    "    \"basal cell carcinoma\": \"bas-class\",\n",
    "    \"folliculitis\": \"fol-class\",\n",
    "    \"nematode infection\": \"nem-class\",\n",
    "    \"neutrophilic dermatoses\": \"neu-class\",\n",
    "    \"prurigo nodularis\": \"pru-class\",\n",
    "    \"psoriasis\": \"pso-class\",\n",
    "    \"squamous cell carcinoma\": \"squ-class\",\n",
    "}\n",
    "\n",
    "skin_type_mapper = {\n",
    "    1: 'a very light-skinned',\n",
    "    2: 'a light-skinned',\n",
    "    5: 'a dark-skinned',\n",
    "    6: 'a very dark-skinned',\n",
    "}\n",
    "\n",
    "output_to_json = []\n",
    "for i, row in df_train.iterrows():\n",
    "    image_path = row['md5hash'] + '.jpg'\n",
    "    label = row['label']\n",
    "    fst = row['fitzpatrick_scale']\n",
    "    disease_token = token_mapper[label]\n",
    "    skin_type = skin_type_mapper[fst]\n",
    "    prompt = f\"An image of {disease_token} on the skin of {skin_type} individual\"\n",
    "    output_to_json.append({\n",
    "        'image_path': image_path,\n",
    "        'label': label,\n",
    "        'skin_type': fst,\n",
    "        'prompt': prompt\n",
    "    })\n",
    "\n",
    "with open(f\"../data_splits/train_lora_{SPLIT}_seed={SEED}.json\", \"w\") as f:\n",
    "        json.dump(output_to_json, f, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for lora training, we use a json file to manage the training data with images and prompts\n",
    "### note that, here, we should put the learned lesion token names derived from textual inversion\n",
    "### in the prompts, instead of the original disease names. Feel free to try different rank sizes.\n",
    "\n",
    "LORA_OUTPUT_DIR=f\"../models/lora_weights/{SPLIT}_seed={SEED}\"\n",
    "json_path = f\"../data_splits/train_lora_{SPLIT}_seed={SEED}.json\"\n",
    "\n",
    "!accelerate launch --mixed_precision=\"fp16\"  ../scripts/train_text_to_image_lora.py \\\n",
    "    --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "    --train_data_dir=$TRAIN_DIR \\\n",
    "    --dataloader_num_workers=8 \\\n",
    "    --image_column=\"image\" \\\n",
    "    --caption_column=\"prompt\" \\\n",
    "    --resolution=512 \\\n",
    "    --train_batch_size=4 \\\n",
    "    --gradient_accumulation_steps=1 \\\n",
    "    --max_train_steps=3000 \\\n",
    "    --learning_rate=5e-06 \\\n",
    "    --max_grad_norm=1 \\\n",
    "    --lr_scheduler=\"constant\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --output_dir=$LORA_OUTPUT_DIR \\\n",
    "    --checkpointing_steps=1000 \\\n",
    "    --rank=8 \\\n",
    "    --embed_path=$TI_EMBED_PATH \\\n",
    "    --json_path=$json_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skin-diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
