{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "SEED = 0\n",
    "SPLIT = \"light_dark_seed_to_dark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge all the learned embeddings into a single file\n",
    "\n",
    "OUTPUT_DIR_BASE = f\"/textual_inversion_weights/{SPLIT}/SEED={SEED}\"\n",
    "path = f\"{OUTPUT_DIR_BASE}/*/learned_embeds.safetensors\"\n",
    "merged_dict = dict()\n",
    "for file in glob.glob(path):\n",
    "    tensors = {}\n",
    "    with safe_open(file, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            tensors[key] = f.get_tensor(key)\n",
    "        merged_dict.update(tensors)\n",
    "\n",
    "target_path = f\"{OUTPUT_DIR_BASE}/aggregated_embeds_SEED={SEED}.pt\"\n",
    "os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "torch.save(merged_dict, target_path)\n",
    "print(merged_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# prompt_mapper = [\n",
    "#     \"<basal_cell_carcinoma>\",\n",
    "#     \"<folliculitis>\",\n",
    "#     \"<nematode_infection>\",\n",
    "#     \"<neutrophilic_dermatoses>\",\n",
    "#     \"<prurigo_nodularis>\",\n",
    "#     \"<psoriasis>\",\n",
    "#     \"<squamous_cell_carcinoma>\",\n",
    "# ]\n",
    "\n",
    "prompt_mapper = [\n",
    "    \"<bas-class>\",\n",
    "    \"<fol-class>\",\n",
    "    \"<nem-class>\",\n",
    "    \"<neu-class>\",\n",
    "    \"<pru-class>\",\n",
    "    \"<pso-class>\",\n",
    "    \"<squ-class>\",\n",
    "]\n",
    "\n",
    "diseases_name = [\n",
    "    \"basal cell carcinoma\",\n",
    "    \"folliculitis\",\n",
    "    \"nematode infection\",\n",
    "    \"neutrophilic dermatoses\",\n",
    "    \"prurigo nodularis\",\n",
    "    \"psoriasis\",\n",
    "    \"squamous cell carcinoma\",\n",
    "]\n",
    "\n",
    "# class_mapper = {\n",
    "#     \"basal cell carcinoma\":     0,\n",
    "#     \"folliculitis\":             1,\n",
    "#     \"nematode infection\":       2,\n",
    "#     \"neutrophilic dermatoses\":  3,\n",
    "#     \"prurigo nodularis\":        4,\n",
    "#     \"psoriasis\":                5,\n",
    "#     \"squamous cell carcinoma\":  6,\n",
    "# }\n",
    "\n",
    "skin_types = {\n",
    "    1: 'a very light-skinned',\n",
    "    2: 'a light-skinned',\n",
    "    5: 'a dark-skinned',\n",
    "    6: 'a very dark-skinned',\n",
    "}\n",
    "\n",
    "### if you want to use images of light skin only for training, comment out the last two parts in the concept list. \n",
    "def make_concepts_list(d_prompt, disease): \n",
    "    concepts_list = [\n",
    "        {\n",
    "            \"instance_prompt\":      f\"An image of {d_prompt} on the skin of a very light-skinned individual\",\n",
    "            \"instance_data_dir\":    f\"data/data_seed={SEED}/1/{disease}\",\n",
    "            \"class_prompt\":         \"An image of the skin of a very light-skinned individual\",\n",
    "            \"class_data_dir\":       f\"data/very_light_skin/\",\n",
    "            \"label\":                0,\n",
    "        },\n",
    "        {\n",
    "            \"instance_prompt\":       f\"An image of {d_prompt} on the skin of a light-skinned individual\",\n",
    "            \"instance_data_dir\":    f\"data/data_seed={SEED}/2/{disease}\",\n",
    "            \"class_prompt\":         \"An image of the skin of a light-skinned individual\",\n",
    "            \"class_data_dir\":       f\"data/light_skin/\",\n",
    "            \"label\":                1,\n",
    "    },\n",
    "        {\n",
    "            \"instance_prompt\":       f\"An image of {d_prompt} on the skin of a dark-skinned individual\",\n",
    "            \"instance_data_dir\":    f\"data/data_seed={SEED}/flexible/5/{disease}\", \n",
    "            \"class_prompt\":         \"An image of the skin of a dark-skinned individual\",\n",
    "            \"class_data_dir\":       f\"data/dark_skin/\",\n",
    "            \"label\":                2,\n",
    "\n",
    "    },\n",
    "        {\n",
    "            \"instance_prompt\":       f\"An image of {d_prompt} on the skin of a very dark-skinned individual\",\n",
    "            \"instance_data_dir\":    f\"data/data_seed={SEED}/flexible/6/{disease}\",\n",
    "            \"class_prompt\":         \"An image of the skin of a very dark-skinned individual\",\n",
    "            \"class_data_dir\":       f\"data/very_dark_skin/\",\n",
    "            \"label\":                3,\n",
    "    },\n",
    "    ]\n",
    "\n",
    "    for c in concepts_list:\n",
    "        os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
    "\n",
    "    with open(f\"ti_lora_concepts_list_seed={SPLIT}_{SEED}.json\", \"w\") as f:\n",
    "        json.dump(concepts_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bas-class> basal cell carcinoma\n",
      "[*] Weights will be saved at textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas\n",
      "03/02/2024 22:03:01 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'clip_sample_range', 'thresholding', 'dynamic_thresholding_ratio', 'timestep_spacing', 'variance_type', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'addition_time_embed_dim', 'time_embedding_act_fn', 'conv_in_kernel', 'num_attention_heads', 'addition_embed_type_num_heads', 'dim_in', 'resnet_skip_time_act', 'resnet_out_scale_factor', 'transformer_layers_per_block', 'resnet_time_scale_shift', 'mid_block_type', 'dropout', 'projection_class_embeddings_input_dim', 'encoder_hid_dim', 'time_cond_proj_dim', 'upcast_attention', 'conv_out_kernel', 'feat_dim', 'class_embed_type', 'timestep_post_act', 'time_embedding_type', 'time_embedding_dim', 'mid_block_only_cross_attention', 'addition_embed_type', 'attention_type', 'head', 'encoder_hid_dim_type', 'cross_attention_norm', 'class_embeddings_concat'} was not found in config. Values will be initialized to default values.\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1ea2a0>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1e9a90>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1eaea0>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1cfe30>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1ce9c0>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc6186cf260>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc6186ce6c0>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc6186ce2a0>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68b845100>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1ccd10>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc6186cc080>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68acaf2f0>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a180260>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a180470>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a180b60>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a180d70>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a181460>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a181670>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1e95e0>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1821b0>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a182840>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a182a80>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1831a0>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a1833b0>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a183d10>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a183f20>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a0385f0>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a038800>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a038ef0>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc68a039100>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc6186ceb40>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fc6186cf1a0>\n",
      "3000\n",
      "03/02/2024 22:04:32 - INFO - __main__ - ***** Running training *****\n",
      "03/02/2024 22:04:32 - INFO - __main__ -   Num examples = 241\n",
      "03/02/2024 22:04:32 - INFO - __main__ -   Num instance images = 241\n",
      "03/02/2024 22:04:32 - INFO - __main__ -   Num batches each epoch = 61\n",
      "03/02/2024 22:04:32 - INFO - __main__ -   Num Epochs = 50\n",
      "03/02/2024 22:04:32 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "03/02/2024 22:04:32 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/02/2024 22:04:32 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "03/02/2024 22:04:32 - INFO - __main__ -   Total optimization steps = 3000\n",
      "Steps:  17%|█▋        | 500/3000 [06:46<34:07,  1.22it/s, loss=0.00565, lr=5e-6]03/02/2024 22:11:18 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-500\n",
      "[2024-03-02 22:11:18,955] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "03/02/2024 22:11:19 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-500/optimizer.bin\n",
      "03/02/2024 22:11:19 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-500/scheduler.bin\n",
      "03/02/2024 22:11:19 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-500/sampler.bin\n",
      "03/02/2024 22:11:19 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-500/scaler.pt\n",
      "03/02/2024 22:11:19 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-500/random_states_0.pkl\n",
      "03/02/2024 22:11:19 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-500\n",
      "Steps:  33%|███▋       | 1000/3000 [13:30<27:17,  1.22it/s, loss=0.224, lr=5e-6]03/02/2024 22:18:02 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "03/02/2024 22:18:02 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1000/optimizer.bin\n",
      "03/02/2024 22:18:02 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1000/scheduler.bin\n",
      "03/02/2024 22:18:02 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1000/sampler.bin\n",
      "03/02/2024 22:18:02 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1000/scaler.pt\n",
      "03/02/2024 22:18:02 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1000/random_states_0.pkl\n",
      "03/02/2024 22:18:02 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1000\n",
      "Steps:  50%|█████▌     | 1500/3000 [20:14<20:24,  1.23it/s, loss=0.199, lr=5e-6]03/02/2024 22:24:46 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1500/pytorch_lora_weights.safetensors\n",
      "03/02/2024 22:24:46 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1500/optimizer.bin\n",
      "03/02/2024 22:24:46 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1500/scheduler.bin\n",
      "03/02/2024 22:24:46 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1500/sampler.bin\n",
      "03/02/2024 22:24:46 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1500/scaler.pt\n",
      "03/02/2024 22:24:46 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1500/random_states_0.pkl\n",
      "03/02/2024 22:24:46 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-1500\n",
      "Steps:  67%|███████▎   | 2000/3000 [26:57<13:35,  1.23it/s, loss=0.147, lr=5e-6]03/02/2024 22:31:29 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2000/pytorch_lora_weights.safetensors\n",
      "03/02/2024 22:31:29 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2000/optimizer.bin\n",
      "03/02/2024 22:31:29 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2000/scheduler.bin\n",
      "03/02/2024 22:31:29 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2000/sampler.bin\n",
      "03/02/2024 22:31:29 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2000/scaler.pt\n",
      "03/02/2024 22:31:29 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2000/random_states_0.pkl\n",
      "03/02/2024 22:31:29 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2000\n",
      "Steps:  83%|█████████▏ | 2500/3000 [33:41<06:44,  1.24it/s, loss=0.341, lr=5e-6]03/02/2024 22:38:13 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2500/pytorch_lora_weights.safetensors\n",
      "03/02/2024 22:38:13 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2500/optimizer.bin\n",
      "03/02/2024 22:38:13 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2500/scheduler.bin\n",
      "03/02/2024 22:38:13 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2500/sampler.bin\n",
      "03/02/2024 22:38:13 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2500/scaler.pt\n",
      "03/02/2024 22:38:13 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2500/random_states_0.pkl\n",
      "03/02/2024 22:38:13 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-2500\n",
      "Steps: 100%|███████████| 3000/3000 [40:13<00:00,  2.55it/s, loss=0.123, lr=5e-6]03/02/2024 22:44:45 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-3000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-3000/pytorch_lora_weights.safetensors\n",
      "03/02/2024 22:44:45 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-3000/optimizer.bin\n",
      "03/02/2024 22:44:45 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-3000/scheduler.bin\n",
      "03/02/2024 22:44:45 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-3000/sampler.bin\n",
      "03/02/2024 22:44:45 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-3000/scaler.pt\n",
      "03/02/2024 22:44:45 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-3000/random_states_0.pkl\n",
      "03/02/2024 22:44:45 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/checkpoint-3000\n",
      "Steps: 100%|███████████| 3000/3000 [40:13<00:00,  2.55it/s, loss=0.119, lr=5e-6]Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/bas/pytorch_lora_weights.safetensors\n",
      "Steps: 100%|███████████| 3000/3000 [40:13<00:00,  1.24it/s, loss=0.119, lr=5e-6]\n",
      "<fol-class> folliculitis\n",
      "[*] Weights will be saved at textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol\n",
      "03/02/2024 22:44:52 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'thresholding', 'dynamic_thresholding_ratio', 'clip_sample_range', 'sample_max_value', 'variance_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'addition_embed_type_num_heads', 'resnet_time_scale_shift', 'addition_embed_type', 'addition_time_embed_dim', 'num_attention_heads', 'dim_in', 'encoder_hid_dim', 'head', 'resnet_out_scale_factor', 'mid_block_type', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'time_cond_proj_dim', 'resnet_skip_time_act', 'attention_type', 'encoder_hid_dim_type', 'class_embeddings_concat', 'time_embedding_act_fn', 'feat_dim', 'conv_in_kernel', 'mid_block_only_cross_attention', 'class_embed_type', 'timestep_post_act', 'dropout', 'conv_out_kernel', 'transformer_layers_per_block', 'cross_attention_norm', 'time_embedding_dim', 'upcast_attention'} was not found in config. Values will be initialized to default values.\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c40bb16d0>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c40bb3d70>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c6a6af770>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c696affb0>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c696afc80>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c696aea50>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8bef995c40>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c696ae270>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8bef995430>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c696ae510>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c6af0f2f0>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8bef9970b0>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c695600e0>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69560320>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c695609b0>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69560bc0>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c40bb1040>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c695614f0>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69561e20>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69561f70>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69562600>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69562840>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69562f00>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69563110>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69563950>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69563b60>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69414260>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69414470>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69414b60>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8c69414d70>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8bef996ae0>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f8bef997170>\n",
      "3000\n",
      "03/02/2024 22:46:23 - INFO - __main__ - ***** Running training *****\n",
      "03/02/2024 22:46:23 - INFO - __main__ -   Num examples = 127\n",
      "03/02/2024 22:46:23 - INFO - __main__ -   Num instance images = 127\n",
      "03/02/2024 22:46:23 - INFO - __main__ -   Num batches each epoch = 32\n",
      "03/02/2024 22:46:23 - INFO - __main__ -   Num Epochs = 94\n",
      "03/02/2024 22:46:23 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "03/02/2024 22:46:23 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/02/2024 22:46:23 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "03/02/2024 22:46:23 - INFO - __main__ -   Total optimization steps = 3000\n",
      "Steps:  17%|█▋        | 500/3000 [06:47<34:00,  1.23it/s, loss=0.00688, lr=5e-6]03/02/2024 22:53:10 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-500\n",
      "[2024-03-02 22:53:10,686] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "03/02/2024 22:53:10 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-500/optimizer.bin\n",
      "03/02/2024 22:53:10 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-500/scheduler.bin\n",
      "03/02/2024 22:53:10 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-500/sampler.bin\n",
      "03/02/2024 22:53:10 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-500/scaler.pt\n",
      "03/02/2024 22:53:10 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-500/random_states_0.pkl\n",
      "03/02/2024 22:53:10 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-500\n",
      "Steps:  33%|████        | 1000/3000 [13:31<27:10,  1.23it/s, loss=0.25, lr=5e-6]03/02/2024 22:59:54 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "03/02/2024 22:59:54 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1000/optimizer.bin\n",
      "03/02/2024 22:59:54 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1000/scheduler.bin\n",
      "03/02/2024 22:59:54 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1000/sampler.bin\n",
      "03/02/2024 22:59:54 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1000/scaler.pt\n",
      "03/02/2024 22:59:54 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1000/random_states_0.pkl\n",
      "03/02/2024 22:59:54 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1000\n",
      "Steps:  50%|█████▌     | 1500/3000 [20:15<20:14,  1.23it/s, loss=0.209, lr=5e-6]03/02/2024 23:06:38 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1500/pytorch_lora_weights.safetensors\n",
      "03/02/2024 23:06:38 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1500/optimizer.bin\n",
      "03/02/2024 23:06:38 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1500/scheduler.bin\n",
      "03/02/2024 23:06:38 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1500/sampler.bin\n",
      "03/02/2024 23:06:38 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1500/scaler.pt\n",
      "03/02/2024 23:06:38 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1500/random_states_0.pkl\n",
      "03/02/2024 23:06:38 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-1500\n",
      "Steps:  67%|███████▎   | 2000/3000 [26:59<13:35,  1.23it/s, loss=0.159, lr=5e-6]03/02/2024 23:13:22 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2000/pytorch_lora_weights.safetensors\n",
      "03/02/2024 23:13:23 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2000/optimizer.bin\n",
      "03/02/2024 23:13:23 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2000/scheduler.bin\n",
      "03/02/2024 23:13:23 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2000/sampler.bin\n",
      "03/02/2024 23:13:23 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2000/scaler.pt\n",
      "03/02/2024 23:13:23 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2000/random_states_0.pkl\n",
      "03/02/2024 23:13:23 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2000\n",
      "Steps:  83%|█████████▏ | 2500/3000 [33:43<06:43,  1.24it/s, loss=0.289, lr=5e-6]03/02/2024 23:20:06 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2500/pytorch_lora_weights.safetensors\n",
      "03/02/2024 23:20:06 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2500/optimizer.bin\n",
      "03/02/2024 23:20:06 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2500/scheduler.bin\n",
      "03/02/2024 23:20:06 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2500/sampler.bin\n",
      "03/02/2024 23:20:06 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2500/scaler.pt\n",
      "03/02/2024 23:20:06 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2500/random_states_0.pkl\n",
      "03/02/2024 23:20:06 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-2500\n",
      "Steps: 100%|███████████| 3000/3000 [40:13<00:00,  2.53it/s, loss=0.153, lr=5e-6]03/02/2024 23:26:36 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-3000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-3000/pytorch_lora_weights.safetensors\n",
      "03/02/2024 23:26:36 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-3000/optimizer.bin\n",
      "03/02/2024 23:26:36 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-3000/scheduler.bin\n",
      "03/02/2024 23:26:36 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-3000/sampler.bin\n",
      "03/02/2024 23:26:36 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-3000/scaler.pt\n",
      "03/02/2024 23:26:36 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-3000/random_states_0.pkl\n",
      "03/02/2024 23:26:36 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/checkpoint-3000\n",
      "Steps: 100%|███████████| 3000/3000 [40:13<00:00,  2.53it/s, loss=0.107, lr=5e-6]Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/fol/pytorch_lora_weights.safetensors\n",
      "Steps: 100%|███████████| 3000/3000 [40:13<00:00,  1.24it/s, loss=0.107, lr=5e-6]\n",
      "<nem-class> nematode infection\n",
      "[*] Weights will be saved at textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem\n",
      "03/02/2024 23:26:42 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'dynamic_thresholding_ratio', 'timestep_spacing', 'thresholding', 'clip_sample_range', 'variance_type', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'dropout', 'time_cond_proj_dim', 'num_attention_heads', 'cross_attention_norm', 'class_embeddings_concat', 'upcast_attention', 'transformer_layers_per_block', 'head', 'mid_block_only_cross_attention', 'resnet_skip_time_act', 'resnet_time_scale_shift', 'addition_embed_type_num_heads', 'timestep_post_act', 'attention_type', 'time_embedding_type', 'time_embedding_dim', 'conv_out_kernel', 'time_embedding_act_fn', 'dim_in', 'addition_embed_type', 'mid_block_type', 'feat_dim', 'encoder_hid_dim', 'projection_class_embeddings_input_dim', 'encoder_hid_dim_type', 'class_embed_type', 'conv_in_kernel', 'resnet_out_scale_factor', 'addition_time_embed_dim'} was not found in config. Values will be initialized to default values.\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a60c20>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a629f0>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a63bc0>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a3b7d0>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1ac1760>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1ac1370>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a3b2f0>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1ac0320>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1ac2510>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1ac2990>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a954f0>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a95d90>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a95c40>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a94980>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5c0b0>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5c4a0>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5cb90>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5cda0>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5d700>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5d910>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5e090>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5e2a0>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5e8d0>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5eae0>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5f470>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5f680>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5fd10>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f9659f5ff20>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c18c05f0>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c18c0800>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a94200>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f96c1a94c80>\n",
      "3000\n",
      "03/02/2024 23:28:13 - INFO - __main__ - ***** Running training *****\n",
      "03/02/2024 23:28:13 - INFO - __main__ -   Num examples = 71\n",
      "03/02/2024 23:28:13 - INFO - __main__ -   Num instance images = 71\n",
      "03/02/2024 23:28:13 - INFO - __main__ -   Num batches each epoch = 18\n",
      "03/02/2024 23:28:13 - INFO - __main__ -   Num Epochs = 167\n",
      "03/02/2024 23:28:13 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "03/02/2024 23:28:13 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/02/2024 23:28:13 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "03/02/2024 23:28:13 - INFO - __main__ -   Total optimization steps = 3000\n",
      "Steps:  17%|█▋        | 500/3000 [06:45<34:03,  1.22it/s, loss=0.00624, lr=5e-6]03/02/2024 23:34:58 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-500\n",
      "[2024-03-02 23:34:59,000] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "03/02/2024 23:34:59 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-500/optimizer.bin\n",
      "03/02/2024 23:34:59 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-500/scheduler.bin\n",
      "03/02/2024 23:34:59 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-500/sampler.bin\n",
      "03/02/2024 23:34:59 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-500/scaler.pt\n",
      "03/02/2024 23:34:59 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-500/random_states_0.pkl\n",
      "03/02/2024 23:34:59 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-500\n",
      "Steps:  33%|███▋       | 1000/3000 [13:27<26:21,  1.26it/s, loss=0.197, lr=5e-6]03/02/2024 23:41:40 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "03/02/2024 23:41:40 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1000/optimizer.bin\n",
      "03/02/2024 23:41:40 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1000/scheduler.bin\n",
      "03/02/2024 23:41:40 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1000/sampler.bin\n",
      "03/02/2024 23:41:40 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1000/scaler.pt\n",
      "03/02/2024 23:41:40 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1000/random_states_0.pkl\n",
      "03/02/2024 23:41:40 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1000\n",
      "Steps:  50%|█████▌     | 1500/3000 [20:08<20:10,  1.24it/s, loss=0.201, lr=5e-6]03/02/2024 23:48:22 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1500/pytorch_lora_weights.safetensors\n",
      "03/02/2024 23:48:22 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1500/optimizer.bin\n",
      "03/02/2024 23:48:22 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1500/scheduler.bin\n",
      "03/02/2024 23:48:22 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1500/sampler.bin\n",
      "03/02/2024 23:48:22 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1500/scaler.pt\n",
      "03/02/2024 23:48:22 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1500/random_states_0.pkl\n",
      "03/02/2024 23:48:22 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-1500\n",
      "Steps:  67%|████████    | 2000/3000 [26:50<13:17,  1.25it/s, loss=0.12, lr=5e-6]03/02/2024 23:55:04 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2000/pytorch_lora_weights.safetensors\n",
      "03/02/2024 23:55:04 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2000/optimizer.bin\n",
      "03/02/2024 23:55:04 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2000/scheduler.bin\n",
      "03/02/2024 23:55:04 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2000/sampler.bin\n",
      "03/02/2024 23:55:04 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2000/scaler.pt\n",
      "03/02/2024 23:55:04 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2000/random_states_0.pkl\n",
      "03/02/2024 23:55:04 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2000\n",
      "Steps:  83%|█████████▏ | 2500/3000 [33:32<06:48,  1.22it/s, loss=0.305, lr=5e-6]03/03/2024 00:01:45 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 00:01:45 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2500/optimizer.bin\n",
      "03/03/2024 00:01:45 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2500/scheduler.bin\n",
      "03/03/2024 00:01:45 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2500/sampler.bin\n",
      "03/03/2024 00:01:45 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2500/scaler.pt\n",
      "03/03/2024 00:01:45 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2500/random_states_0.pkl\n",
      "03/03/2024 00:01:45 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-2500\n",
      "Steps: 100%|███████████| 3000/3000 [39:57<00:00,  2.52it/s, loss=0.118, lr=5e-6]03/03/2024 00:08:10 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-3000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-3000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 00:08:10 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-3000/optimizer.bin\n",
      "03/03/2024 00:08:10 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-3000/scheduler.bin\n",
      "03/03/2024 00:08:10 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-3000/sampler.bin\n",
      "03/03/2024 00:08:10 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-3000/scaler.pt\n",
      "03/03/2024 00:08:10 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-3000/random_states_0.pkl\n",
      "03/03/2024 00:08:10 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/checkpoint-3000\n",
      "Steps: 100%|███████████| 3000/3000 [39:57<00:00,  2.52it/s, loss=0.106, lr=5e-6]Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/nem/pytorch_lora_weights.safetensors\n",
      "Steps: 100%|███████████| 3000/3000 [39:57<00:00,  1.25it/s, loss=0.106, lr=5e-6]\n",
      "<neu-class> neutrophilic dermatoses\n",
      "[*] Weights will be saved at textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu\n",
      "03/03/2024 00:08:17 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'thresholding', 'timestep_spacing', 'dynamic_thresholding_ratio', 'clip_sample_range', 'sample_max_value', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'addition_embed_type_num_heads', 'resnet_skip_time_act', 'dropout', 'attention_type', 'addition_time_embed_dim', 'addition_embed_type', 'time_embedding_act_fn', 'class_embed_type', 'class_embeddings_concat', 'mid_block_type', 'time_cond_proj_dim', 'dim_in', 'resnet_out_scale_factor', 'projection_class_embeddings_input_dim', 'conv_in_kernel', 'mid_block_only_cross_attention', 'encoder_hid_dim_type', 'time_embedding_type', 'timestep_post_act', 'cross_attention_norm', 'upcast_attention', 'head', 'transformer_layers_per_block', 'conv_out_kernel', 'encoder_hid_dim', 'num_attention_heads', 'feat_dim', 'resnet_time_scale_shift', 'time_embedding_dim'} was not found in config. Values will be initialized to default values.\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f83b7d0>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f839c10>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f83bbc0>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f9d97c0>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f9dbc80>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f9d9af0>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7ecd40>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7eccb0>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa105cc3a70>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f83b440>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa105cc2a20>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa105cc24e0>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa105cc1790>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa105cc1f10>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa105cc3650>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa105cc3cb0>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7b83e0>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7b85f0>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7b8f80>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7b9190>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7b9820>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7b9a60>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7ba180>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7ba390>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f83ab10>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7bae40>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f838110>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7bb6e0>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7bbe30>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f7bbf50>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f9d94f0>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fa17f9d8d40>\n",
      "3000\n",
      "03/03/2024 00:09:47 - INFO - __main__ - ***** Running training *****\n",
      "03/03/2024 00:09:47 - INFO - __main__ -   Num examples = 185\n",
      "03/03/2024 00:09:47 - INFO - __main__ -   Num instance images = 185\n",
      "03/03/2024 00:09:47 - INFO - __main__ -   Num batches each epoch = 47\n",
      "03/03/2024 00:09:47 - INFO - __main__ -   Num Epochs = 64\n",
      "03/03/2024 00:09:47 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "03/03/2024 00:09:47 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/03/2024 00:09:47 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "03/03/2024 00:09:47 - INFO - __main__ -   Total optimization steps = 3000\n",
      "Steps:  17%|█▋        | 500/3000 [06:45<33:04,  1.26it/s, loss=0.00702, lr=5e-6]03/03/2024 00:16:32 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-500\n",
      "[2024-03-03 00:16:32,951] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 00:16:33 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-500/optimizer.bin\n",
      "03/03/2024 00:16:33 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-500/scheduler.bin\n",
      "03/03/2024 00:16:33 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-500/sampler.bin\n",
      "03/03/2024 00:16:33 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-500/scaler.pt\n",
      "03/03/2024 00:16:33 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-500/random_states_0.pkl\n",
      "03/03/2024 00:16:33 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-500\n",
      "Steps:  33%|███▋       | 1000/3000 [13:26<27:13,  1.22it/s, loss=0.183, lr=5e-6]03/03/2024 00:23:14 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 00:23:14 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1000/optimizer.bin\n",
      "03/03/2024 00:23:14 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1000/scheduler.bin\n",
      "03/03/2024 00:23:14 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1000/sampler.bin\n",
      "03/03/2024 00:23:14 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1000/scaler.pt\n",
      "03/03/2024 00:23:14 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1000/random_states_0.pkl\n",
      "03/03/2024 00:23:14 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1000\n",
      "Steps:  50%|█████▌     | 1500/3000 [20:09<20:27,  1.22it/s, loss=0.198, lr=5e-6]03/03/2024 00:29:56 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 00:29:57 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1500/optimizer.bin\n",
      "03/03/2024 00:29:57 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1500/scheduler.bin\n",
      "03/03/2024 00:29:57 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1500/sampler.bin\n",
      "03/03/2024 00:29:57 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1500/scaler.pt\n",
      "03/03/2024 00:29:57 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1500/random_states_0.pkl\n",
      "03/03/2024 00:29:57 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-1500\n",
      "Steps:  67%|███████▎   | 2000/3000 [26:51<13:35,  1.23it/s, loss=0.155, lr=5e-6]03/03/2024 00:36:38 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 00:36:38 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2000/optimizer.bin\n",
      "03/03/2024 00:36:38 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2000/scheduler.bin\n",
      "03/03/2024 00:36:38 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2000/sampler.bin\n",
      "03/03/2024 00:36:38 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2000/scaler.pt\n",
      "03/03/2024 00:36:38 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2000/random_states_0.pkl\n",
      "03/03/2024 00:36:38 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2000\n",
      "Steps:  83%|█████████▏ | 2500/3000 [33:32<06:45,  1.23it/s, loss=0.324, lr=5e-6]03/03/2024 00:43:20 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 00:43:20 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2500/optimizer.bin\n",
      "03/03/2024 00:43:20 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2500/scheduler.bin\n",
      "03/03/2024 00:43:20 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2500/sampler.bin\n",
      "03/03/2024 00:43:20 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2500/scaler.pt\n",
      "03/03/2024 00:43:20 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2500/random_states_0.pkl\n",
      "03/03/2024 00:43:20 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-2500\n",
      "Steps: 100%|███████████| 3000/3000 [39:56<00:00,  2.52it/s, loss=0.144, lr=5e-6]03/03/2024 00:49:44 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-3000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-3000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 00:49:44 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-3000/optimizer.bin\n",
      "03/03/2024 00:49:44 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-3000/scheduler.bin\n",
      "03/03/2024 00:49:44 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-3000/sampler.bin\n",
      "03/03/2024 00:49:44 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-3000/scaler.pt\n",
      "03/03/2024 00:49:44 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-3000/random_states_0.pkl\n",
      "03/03/2024 00:49:44 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/checkpoint-3000\n",
      "Steps: 100%|███████████| 3000/3000 [39:57<00:00,  2.52it/s, loss=0.119, lr=5e-6]Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/neu/pytorch_lora_weights.safetensors\n",
      "Steps: 100%|███████████| 3000/3000 [39:57<00:00,  1.25it/s, loss=0.119, lr=5e-6]\n",
      "<pru-class> prurigo nodularis\n",
      "[*] Weights will be saved at textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru\n",
      "03/03/2024 00:49:50 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'clip_sample_range', 'timestep_spacing', 'dynamic_thresholding_ratio', 'thresholding', 'sample_max_value', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'dropout', 'encoder_hid_dim', 'encoder_hid_dim_type', 'transformer_layers_per_block', 'resnet_out_scale_factor', 'addition_time_embed_dim', 'resnet_skip_time_act', 'time_embedding_dim', 'addition_embed_type_num_heads', 'mid_block_only_cross_attention', 'class_embeddings_concat', 'feat_dim', 'timestep_post_act', 'conv_in_kernel', 'addition_embed_type', 'num_attention_heads', 'dim_in', 'class_embed_type', 'resnet_time_scale_shift', 'attention_type', 'conv_out_kernel', 'time_embedding_type', 'time_embedding_act_fn', 'upcast_attention', 'cross_attention_norm', 'head', 'mid_block_type', 'time_cond_proj_dim', 'projection_class_embeddings_input_dim'} was not found in config. Values will be initialized to default values.\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd63290>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd61b20>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd63f50>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd623f0>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd31b80>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd33710>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd33f20>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd322a0>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f01b8e12c00>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f01b8e138f0>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f01b8e12ea0>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f01b8e12ab0>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f01b8e11880>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd620f0>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f01b8e13620>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f01b8e13bf0>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dae8320>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd30500>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dae8d70>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dae8f80>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dae9640>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dae9880>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dae9fa0>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021daea240>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021daeab10>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021dd32b10>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021daeb2f0>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021f41b4a0>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021daebbc0>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f021daebdd0>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f01b8e11250>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f01b8e10e90>\n",
      "3000\n",
      "03/03/2024 00:51:22 - INFO - __main__ - ***** Running training *****\n",
      "03/03/2024 00:51:22 - INFO - __main__ -   Num examples = 35\n",
      "03/03/2024 00:51:22 - INFO - __main__ -   Num instance images = 35\n",
      "03/03/2024 00:51:22 - INFO - __main__ -   Num batches each epoch = 9\n",
      "03/03/2024 00:51:22 - INFO - __main__ -   Num Epochs = 334\n",
      "03/03/2024 00:51:22 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "03/03/2024 00:51:22 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/03/2024 00:51:22 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "03/03/2024 00:51:22 - INFO - __main__ -   Total optimization steps = 3000\n",
      "Steps:  17%|█▋        | 500/3000 [06:36<33:20,  1.25it/s, loss=0.00618, lr=5e-6]03/03/2024 00:57:58 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-500\n",
      "[2024-03-03 00:57:58,606] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 00:57:58 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-500/optimizer.bin\n",
      "03/03/2024 00:57:58 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-500/scheduler.bin\n",
      "03/03/2024 00:57:58 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-500/sampler.bin\n",
      "03/03/2024 00:57:58 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-500/scaler.pt\n",
      "03/03/2024 00:57:58 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-500/random_states_0.pkl\n",
      "03/03/2024 00:57:58 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-500\n",
      "Steps:  33%|███▎      | 1000/3000 [13:09<25:02,  1.33it/s, loss=0.0936, lr=5e-6]03/03/2024 01:04:31 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 01:04:31 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1000/optimizer.bin\n",
      "03/03/2024 01:04:31 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1000/scheduler.bin\n",
      "03/03/2024 01:04:31 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1000/sampler.bin\n",
      "03/03/2024 01:04:31 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1000/scaler.pt\n",
      "03/03/2024 01:04:31 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1000/random_states_0.pkl\n",
      "03/03/2024 01:04:31 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1000\n",
      "Steps:  50%|█████▌     | 1500/3000 [19:42<20:04,  1.25it/s, loss=0.186, lr=5e-6]03/03/2024 01:11:05 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 01:11:05 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1500/optimizer.bin\n",
      "03/03/2024 01:11:05 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1500/scheduler.bin\n",
      "03/03/2024 01:11:05 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1500/sampler.bin\n",
      "03/03/2024 01:11:05 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1500/scaler.pt\n",
      "03/03/2024 01:11:05 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1500/random_states_0.pkl\n",
      "03/03/2024 01:11:05 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-1500\n",
      "Steps:  67%|███████▎   | 2000/3000 [26:16<13:15,  1.26it/s, loss=0.127, lr=5e-6]03/03/2024 01:17:38 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 01:17:38 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2000/optimizer.bin\n",
      "03/03/2024 01:17:38 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2000/scheduler.bin\n",
      "03/03/2024 01:17:38 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2000/sampler.bin\n",
      "03/03/2024 01:17:38 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2000/scaler.pt\n",
      "03/03/2024 01:17:38 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2000/random_states_0.pkl\n",
      "03/03/2024 01:17:38 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2000\n",
      "Steps:  83%|█████████▏ | 2500/3000 [32:49<06:37,  1.26it/s, loss=0.281, lr=5e-6]03/03/2024 01:24:11 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 01:24:11 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2500/optimizer.bin\n",
      "03/03/2024 01:24:11 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2500/scheduler.bin\n",
      "03/03/2024 01:24:11 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2500/sampler.bin\n",
      "03/03/2024 01:24:11 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2500/scaler.pt\n",
      "03/03/2024 01:24:11 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2500/random_states_0.pkl\n",
      "03/03/2024 01:24:11 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-2500\n",
      "Steps: 100%|███████████| 3000/3000 [39:03<00:00,  2.61it/s, loss=0.129, lr=5e-6]03/03/2024 01:30:25 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-3000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-3000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 01:30:25 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-3000/optimizer.bin\n",
      "03/03/2024 01:30:25 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-3000/scheduler.bin\n",
      "03/03/2024 01:30:25 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-3000/sampler.bin\n",
      "03/03/2024 01:30:25 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-3000/scaler.pt\n",
      "03/03/2024 01:30:25 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-3000/random_states_0.pkl\n",
      "03/03/2024 01:30:25 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/checkpoint-3000\n",
      "Steps: 100%|███████████| 3000/3000 [39:03<00:00,  2.61it/s, loss=0.114, lr=5e-6]Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pru/pytorch_lora_weights.safetensors\n",
      "Steps: 100%|███████████| 3000/3000 [39:03<00:00,  1.28it/s, loss=0.114, lr=5e-6]\n",
      "<pso-class> psoriasis\n",
      "[*] Weights will be saved at textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso\n",
      "03/03/2024 01:30:31 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'timestep_spacing', 'thresholding', 'dynamic_thresholding_ratio', 'sample_max_value', 'variance_type', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'resnet_skip_time_act', 'mid_block_only_cross_attention', 'head', 'resnet_time_scale_shift', 'time_cond_proj_dim', 'addition_embed_type', 'upcast_attention', 'feat_dim', 'resnet_out_scale_factor', 'attention_type', 'dropout', 'conv_out_kernel', 'time_embedding_dim', 'encoder_hid_dim_type', 'timestep_post_act', 'projection_class_embeddings_input_dim', 'time_embedding_act_fn', 'time_embedding_type', 'class_embed_type', 'class_embeddings_concat', 'conv_in_kernel', 'cross_attention_norm', 'num_attention_heads', 'transformer_layers_per_block', 'addition_time_embed_dim', 'addition_embed_type_num_heads', 'encoder_hid_dim', 'mid_block_type', 'dim_in'} was not found in config. Values will be initialized to default values.\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a862240>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a862e40>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a4d0980>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a4d1850>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a51c260>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a51f800>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f75109a7bf0>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f75109a6090>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f75109a53a0>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f75109a4f80>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f75109a4140>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f75109a4530>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44c920>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44cb30>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44d220>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44d430>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44daf0>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44dd00>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44e5d0>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44e7b0>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758b445df0>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44eff0>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44f6b0>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a44f8c0>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a51c3b0>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a314410>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a314b00>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a314d10>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a315400>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f758a315610>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f75109a73b0>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7f75109a7710>\n",
      "3000\n",
      "03/03/2024 01:32:02 - INFO - __main__ - ***** Running training *****\n",
      "03/03/2024 01:32:02 - INFO - __main__ -   Num examples = 345\n",
      "03/03/2024 01:32:02 - INFO - __main__ -   Num instance images = 345\n",
      "03/03/2024 01:32:02 - INFO - __main__ -   Num batches each epoch = 87\n",
      "03/03/2024 01:32:02 - INFO - __main__ -   Num Epochs = 35\n",
      "03/03/2024 01:32:02 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "03/03/2024 01:32:02 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/03/2024 01:32:02 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "03/03/2024 01:32:02 - INFO - __main__ -   Total optimization steps = 3000\n",
      "Steps:  17%|█▋        | 500/3000 [06:48<33:57,  1.23it/s, loss=0.00547, lr=5e-6]03/03/2024 01:38:51 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-500\n",
      "[2024-03-03 01:38:51,249] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 01:38:51 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-500/optimizer.bin\n",
      "03/03/2024 01:38:51 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-500/scheduler.bin\n",
      "03/03/2024 01:38:51 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-500/sampler.bin\n",
      "03/03/2024 01:38:51 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-500/scaler.pt\n",
      "03/03/2024 01:38:51 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-500/random_states_0.pkl\n",
      "03/03/2024 01:38:51 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-500\n",
      "Steps:  33%|███▋       | 1000/3000 [13:32<27:12,  1.23it/s, loss=0.208, lr=5e-6]03/03/2024 01:45:35 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 01:45:35 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1000/optimizer.bin\n",
      "03/03/2024 01:45:35 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1000/scheduler.bin\n",
      "03/03/2024 01:45:35 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1000/sampler.bin\n",
      "03/03/2024 01:45:35 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1000/scaler.pt\n",
      "03/03/2024 01:45:35 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1000/random_states_0.pkl\n",
      "03/03/2024 01:45:35 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1000\n",
      "Steps:  50%|█████▌     | 1500/3000 [20:17<20:23,  1.23it/s, loss=0.189, lr=5e-6]03/03/2024 01:52:19 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 01:52:20 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1500/optimizer.bin\n",
      "03/03/2024 01:52:20 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1500/scheduler.bin\n",
      "03/03/2024 01:52:20 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1500/sampler.bin\n",
      "03/03/2024 01:52:20 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1500/scaler.pt\n",
      "03/03/2024 01:52:20 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1500/random_states_0.pkl\n",
      "03/03/2024 01:52:20 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-1500\n",
      "Steps:  67%|████████    | 2000/3000 [27:01<13:34,  1.23it/s, loss=0.12, lr=5e-6]03/03/2024 01:59:04 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 01:59:04 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2000/optimizer.bin\n",
      "03/03/2024 01:59:04 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2000/scheduler.bin\n",
      "03/03/2024 01:59:04 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2000/sampler.bin\n",
      "03/03/2024 01:59:04 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2000/scaler.pt\n",
      "03/03/2024 01:59:04 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2000/random_states_0.pkl\n",
      "03/03/2024 01:59:04 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2000\n",
      "Steps:  83%|█████████▏ | 2500/3000 [33:46<06:42,  1.24it/s, loss=0.323, lr=5e-6]03/03/2024 02:05:49 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 02:05:49 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2500/optimizer.bin\n",
      "03/03/2024 02:05:49 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2500/scheduler.bin\n",
      "03/03/2024 02:05:49 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2500/sampler.bin\n",
      "03/03/2024 02:05:49 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2500/scaler.pt\n",
      "03/03/2024 02:05:49 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2500/random_states_0.pkl\n",
      "03/03/2024 02:05:49 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-2500\n",
      "Steps: 100%|███████████| 3000/3000 [40:07<00:00,  2.57it/s, loss=0.125, lr=5e-6]03/03/2024 02:12:10 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-3000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-3000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 02:12:10 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-3000/optimizer.bin\n",
      "03/03/2024 02:12:10 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-3000/scheduler.bin\n",
      "03/03/2024 02:12:10 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-3000/sampler.bin\n",
      "03/03/2024 02:12:10 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-3000/scaler.pt\n",
      "03/03/2024 02:12:10 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-3000/random_states_0.pkl\n",
      "03/03/2024 02:12:10 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/checkpoint-3000\n",
      "Steps: 100%|███████████| 3000/3000 [40:07<00:00,  2.57it/s, loss=0.123, lr=5e-6]Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/pso/pytorch_lora_weights.safetensors\n",
      "Steps: 100%|███████████| 3000/3000 [40:07<00:00,  1.25it/s, loss=0.123, lr=5e-6]\n",
      "<squ-class> squamous cell carcinoma\n",
      "[*] Weights will be saved at textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ\n",
      "03/03/2024 02:12:16 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'thresholding', 'sample_max_value', 'variance_type', 'timestep_spacing', 'dynamic_thresholding_ratio', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.safetensors file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.safetensors' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "/ssd/janet/lora_textual_inversion/diffusers_/utils/hub_utils.py:314: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2-1-base via `revision='fp16'`. This behavior is deprecated and will be removed in diffusers v1. One should use `variant='fp16'` instead. However, it appears that stabilityai/stable-diffusion-2-1-base currently does not have a diffusion_pytorch_model.fp16.bin file in the 'main' branch of stabilityai/stable-diffusion-2-1-base. \n",
      " The Diffusers team and community would be very grateful if you could open an issue: https://github.com/huggingface/diffusers/issues/new with the title 'stabilityai/stable-diffusion-2-1-base is missing diffusion_pytorch_model.fp16.bin' so that the correct variant file can be added.\n",
      "  warnings.warn(\n",
      "{'force_upcast', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
      "{'addition_embed_type_num_heads', 'resnet_skip_time_act', 'time_embedding_act_fn', 'time_embedding_type', 'mid_block_type', 'dim_in', 'upcast_attention', 'attention_type', 'transformer_layers_per_block', 'time_cond_proj_dim', 'class_embed_type', 'feat_dim', 'num_attention_heads', 'head', 'encoder_hid_dim_type', 'dropout', 'addition_time_embed_dim', 'cross_attention_norm', 'projection_class_embeddings_input_dim', 'conv_in_kernel', 'time_embedding_dim', 'addition_embed_type', 'class_embeddings_concat', 'encoder_hid_dim', 'resnet_time_scale_shift', 'resnet_out_scale_factor', 'conv_out_kernel', 'timestep_post_act', 'mid_block_only_cross_attention'} was not found in config. Values will be initialized to default values.\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb8dcc33500>\n",
      "down_blocks.0.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb90592bd10>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb90585be60>\n",
      "down_blocks.0.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb8dcc7b620>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb8dcc7abd0>\n",
      "down_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb90592a090>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb8dcc78bf0>\n",
      "down_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb8dcc7ba40>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb90592a720>\n",
      "down_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb8dcc323c0>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb88ba59700>\n",
      "down_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb88ba59340>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb88ba5b230>\n",
      "up_blocks.1.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb88ba5b440>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb88ba5bad0>\n",
      "up_blocks.1.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb88ba5bce0>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905650410>\n",
      "up_blocks.1.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb9059285f0>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905650f80>\n",
      "up_blocks.2.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb9065024e0>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905651820>\n",
      "up_blocks.2.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb9056519a0>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905652120>\n",
      "up_blocks.2.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905652270>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905652ab0>\n",
      "up_blocks.3.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905652cc0>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905653320>\n",
      "up_blocks.3.attentions.1.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb9056535c0>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905653bc0>\n",
      "up_blocks.3.attentions.2.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb905653dd0>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn1.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb88ba588f0>\n",
      "mid_block.attentions.0.transformer_blocks.0.attn2.processor <diffusers_.models.attention_processor.AttnProcessor2_0 object at 0x7fb88ba58f80>\n",
      "3000\n",
      "03/03/2024 02:13:46 - INFO - __main__ - ***** Running training *****\n",
      "03/03/2024 02:13:46 - INFO - __main__ -   Num examples = 280\n",
      "03/03/2024 02:13:46 - INFO - __main__ -   Num instance images = 280\n",
      "03/03/2024 02:13:46 - INFO - __main__ -   Num batches each epoch = 70\n",
      "03/03/2024 02:13:46 - INFO - __main__ -   Num Epochs = 43\n",
      "03/03/2024 02:13:46 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "03/03/2024 02:13:46 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "03/03/2024 02:13:46 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "03/03/2024 02:13:46 - INFO - __main__ -   Total optimization steps = 3000\n",
      "Steps:  17%|█▋        | 500/3000 [06:51<33:58,  1.23it/s, loss=0.00549, lr=5e-6]03/03/2024 02:20:38 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-500\n",
      "[2024-03-03 02:20:38,162] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 02:20:38 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-500/optimizer.bin\n",
      "03/03/2024 02:20:38 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-500/scheduler.bin\n",
      "03/03/2024 02:20:38 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-500/sampler.bin\n",
      "03/03/2024 02:20:38 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-500/scaler.pt\n",
      "03/03/2024 02:20:38 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-500/random_states_0.pkl\n",
      "03/03/2024 02:20:38 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-500\n",
      "Steps:  33%|███▋       | 1000/3000 [13:39<27:11,  1.23it/s, loss=0.188, lr=5e-6]03/03/2024 02:27:25 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 02:27:25 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1000/optimizer.bin\n",
      "03/03/2024 02:27:25 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1000/scheduler.bin\n",
      "03/03/2024 02:27:25 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1000/sampler.bin\n",
      "03/03/2024 02:27:25 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1000/scaler.pt\n",
      "03/03/2024 02:27:25 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1000/random_states_0.pkl\n",
      "03/03/2024 02:27:25 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1000\n",
      "Steps:  50%|█████▌     | 1500/3000 [20:26<20:24,  1.22it/s, loss=0.206, lr=5e-6]03/03/2024 02:34:13 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 02:34:13 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1500/optimizer.bin\n",
      "03/03/2024 02:34:13 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1500/scheduler.bin\n",
      "03/03/2024 02:34:13 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1500/sampler.bin\n",
      "03/03/2024 02:34:13 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1500/scaler.pt\n",
      "03/03/2024 02:34:13 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1500/random_states_0.pkl\n",
      "03/03/2024 02:34:13 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-1500\n",
      "Steps:  67%|███████▎   | 2000/3000 [27:14<13:36,  1.23it/s, loss=0.165, lr=5e-6]03/03/2024 02:41:01 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 02:41:01 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2000/optimizer.bin\n",
      "03/03/2024 02:41:01 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2000/scheduler.bin\n",
      "03/03/2024 02:41:01 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2000/sampler.bin\n",
      "03/03/2024 02:41:01 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2000/scaler.pt\n",
      "03/03/2024 02:41:01 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2000/random_states_0.pkl\n",
      "03/03/2024 02:41:01 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2000\n",
      "Steps:  83%|█████████▏ | 2500/3000 [34:01<06:48,  1.22it/s, loss=0.305, lr=5e-6]03/03/2024 02:47:48 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2500\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2500/pytorch_lora_weights.safetensors\n",
      "03/03/2024 02:47:48 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2500/optimizer.bin\n",
      "03/03/2024 02:47:48 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2500/scheduler.bin\n",
      "03/03/2024 02:47:48 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2500/sampler.bin\n",
      "03/03/2024 02:47:48 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2500/scaler.pt\n",
      "03/03/2024 02:47:48 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2500/random_states_0.pkl\n",
      "03/03/2024 02:47:48 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-2500\n",
      "Steps: 100%|███████████| 3000/3000 [40:25<00:00,  2.55it/s, loss=0.136, lr=5e-6]03/03/2024 02:54:12 - INFO - accelerate.accelerator - Saving current state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-3000\n",
      "Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-3000/pytorch_lora_weights.safetensors\n",
      "03/03/2024 02:54:12 - INFO - accelerate.checkpointing - Optimizer state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-3000/optimizer.bin\n",
      "03/03/2024 02:54:12 - INFO - accelerate.checkpointing - Scheduler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-3000/scheduler.bin\n",
      "03/03/2024 02:54:12 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-3000/sampler.bin\n",
      "03/03/2024 02:54:12 - INFO - accelerate.checkpointing - Gradient scaler state saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-3000/scaler.pt\n",
      "03/03/2024 02:54:12 - INFO - accelerate.checkpointing - Random states saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-3000/random_states_0.pkl\n",
      "03/03/2024 02:54:12 - INFO - __main__ - Saved state to textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/checkpoint-3000\n",
      "Steps: 100%|███████████| 3000/3000 [40:25<00:00,  2.55it/s, loss=0.124, lr=5e-6]Model weights saved in textual_inversion_weights/light_dark_seed_to_dark/ti_lora_SEED=1234/squ/pytorch_lora_weights.safetensors\n",
      "Steps: 100%|███████████| 3000/3000 [40:25<00:00,  1.24it/s, loss=0.124, lr=5e-6]\n"
     ]
    }
   ],
   "source": [
    "for dtype in range(7):\n",
    "    d_prompt = prompt_mapper[dtype]\n",
    "    disease = diseases_name[dtype]\n",
    "    print(d_prompt, disease)\n",
    "    make_concepts_list(d_prompt, disease)\n",
    "    concept_list = f\"ti_lora_concepts_list_seed={SPLIT}_{SEED}.json\"\n",
    "\n",
    "    MODEL_NAME = \"stabilityai/stable-diffusion-2-1-base\" \n",
    "    OUTPUT_DIR = f\"textual_inversion_weights/{SPLIT}/ti_lora_SEED={SEED}/{disease[:3]}\"    \n",
    "    embed_path = f\"textual_inversion_weights/{SPLIT}/SEED={SEED}/aggregated_embeds_SEED={SEED}.pt\"\n",
    "\n",
    "    print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
    "    !accelerate launch train_lora.py \\\n",
    "        --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "        --output_dir=$OUTPUT_DIR \\\n",
    "        --revision=\"fp16\" \\\n",
    "        --seed=1337 \\\n",
    "        --resolution=512 \\\n",
    "        --train_batch_size=4 \\\n",
    "        --sample_batch_size=4 \\\n",
    "        --mixed_precision=\"fp16\" \\\n",
    "        --use_8bit_adam \\\n",
    "        --gradient_accumulation_steps=1 \\\n",
    "        --gradient_checkpointing \\\n",
    "        --learning_rate=5e-6 \\\n",
    "        --lr_scheduler=\"constant\" \\\n",
    "        --lr_warmup_steps=0 \\\n",
    "        --max_train_steps=3000 \\\n",
    "        --checkpointing_steps=500 \\\n",
    "        --concepts_list=$concept_list \\\n",
    "        --rank=8 \\\n",
    "        --embed_path=$embed_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "df",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
